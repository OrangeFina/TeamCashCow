{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Tag\n",
    "import pandas as pd\n",
    "import csv\n",
    "import json\n",
    "\n",
    "pages_final = 300\n",
    "page = 0\n",
    "\n",
    "time_results = []\n",
    "title_results = []\n",
    "tag_results = []\n",
    "content_results = []\n",
    "    \n",
    "for item in range(0, pages_final):    \n",
    "    page = int(page)\n",
    "    page = page + 1\n",
    "    page = str(page)\n",
    "    url1 = \"https://www.theverge.com/search?page=\"\n",
    "    url1 += page\n",
    "    url1 += \"&q=apple\"\n",
    "    resp = requests.get(url1)\n",
    "    print(page)\n",
    "\n",
    "    \n",
    "    new_york_soup = BeautifulSoup(resp.text, 'html.parser') #resp.text gives you the entire html code\n",
    "\n",
    "    column_names = ['Date','Title','Tag','Content']\n",
    "\n",
    "    for item in new_york_soup.find_all(\"a\",{\"data-chorus-optimize-field\":\"hed\"}):\n",
    "        _href = item.get(\"href\")\n",
    "        try:\n",
    "            resp = requests.get(_href)\n",
    "        except Exception as e:\n",
    "                continue\n",
    "\n",
    "        sauce = BeautifulSoup(resp.text,\"html.parser\")\n",
    "        dateTag = sauce.find_all(\"time\",{\"class\":\"c-byline__item\"})\n",
    "        tag = sauce.find_all(\"p\",{\"class\":\"c-entry-summary p-dek\"})\n",
    "        titleTag = sauce.find_all(\"h1\",{\"class\":\"c-page-title\"})\n",
    "        contentTag = sauce.find_all(\"div\",{\"class\":\"c-entry-content \"})\n",
    "\n",
    "        for title1 in titleTag:\n",
    "            title_entry = title1.text\n",
    "            title_results.append(title_entry)\n",
    "\n",
    "        for tag1 in tag:\n",
    "            tag_entry = tag1.text\n",
    "            tag_results.append(tag_entry)\n",
    "\n",
    "        for content1 in contentTag:\n",
    "            content_entry = content1.text\n",
    "            content_results.append(content_entry)\n",
    "\n",
    "        for time1 in dateTag:\n",
    "            date_entry = time1.text\n",
    "            time_results.append(date_entry)\n",
    "            \n",
    "        time.sleep(0.5)\n",
    "        \n",
    "time_df = pd.DataFrame(data = time_results)\n",
    "title_df = pd.DataFrame(data = title_results)\n",
    "tag_df = pd.DataFrame(data = tag_results)\n",
    "content_df = pd.DataFrame(data = content_results)\n",
    "\n",
    "\n",
    "all_results= pd.concat([time_df,title_df,tag_df,content_df], axis=1,join='inner')\n",
    "all_results.columns = ['Date','Title','Tag','Content']\n",
    "\n",
    "all_results.to_csv('Apple.csv')\n",
    "all_results.to_json (r'C:\\Users\\Kyle Ker\\Apple.json')\n",
    "\n",
    "all_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
