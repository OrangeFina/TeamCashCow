{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import csv\n",
    "import json \n",
    "\n",
    "# start_date = input('What do you want the start date yyyy-mm-dd for scrapping to be? ')\n",
    "# end_date = input('What do you want the end date yyyy-mm-dd for scrapping to be? ')\n",
    "\n",
    "start_date = '2015-01-01'\n",
    "end_date = '2020-02-28'\n",
    "counter = input('Which company do you want to look at? ')\n",
    "pages_final = 100\n",
    "page = 0\n",
    "\n",
    "# all_results = {}\n",
    "# all_results_1 = {}\n",
    "text1 = []\n",
    "column_names = ['Date','Title','Content']\n",
    "\n",
    "title_results = []\n",
    "content_results = []\n",
    "time_results = []\n",
    "\n",
    "for item in range(0, pages_final):    \n",
    "    page = int(page)\n",
    "    page = page + 1\n",
    "    page = str(page)\n",
    "    url1 = 'https://www.ft.com/search?q='\n",
    "    url1 += counter\n",
    "    url1 += '&page=' + page\n",
    "    url1 += '&dateTo=' + end_date \n",
    "    url1 += '&dateFrom=' + start_date\n",
    "    url1 += '&sort=relevance&expandRefinements=true&contentType=article'\n",
    "    print(url1)\n",
    "\n",
    "    resp = requests.get(url1)\n",
    "\n",
    "    sauce = BeautifulSoup(resp.text, 'html.parser')\n",
    "\n",
    "\n",
    "    title_entry = sauce.find_all(\"a\", attrs = {\"class\": \"js-teaser-heading-link\"})\n",
    "    content_entry = sauce.find_all(\"a\", attrs = {\"class\": \"js-teaser-standfirst-link\"})\n",
    "    time_entry = sauce.find_all(\"time\", attrs = {\"class\": \"o-teaser__timestamp-date\"})\n",
    "\n",
    "    \n",
    "    for title1 in title_entry:\n",
    "        title = title1.text\n",
    "        title_results.append(title)\n",
    "       \n",
    "        \n",
    "    \n",
    "    for content1 in content_entry:\n",
    "        content = content1.text\n",
    "        content_results.append(content)\n",
    "\n",
    "    \n",
    "    for time1 in time_entry:\n",
    "        date = time1.text\n",
    "        time_results.append(date)\n",
    "        \n",
    "    time.sleep(2)\n",
    "    \n",
    "\n",
    "time_df = pd.DataFrame(data = time_results)\n",
    "title_df = pd.DataFrame(data = title_results)\n",
    "content_df = pd.DataFrame(data = content_results)\n",
    "\n",
    "all_results= pd.concat([time_df,title_df,content_df], axis=1,join='inner')\n",
    "all_results.columns = ['Date','Title','Content']\n",
    "\n",
    "\n",
    "all_results.to_csv('Apple_3.csv')\n",
    "\n",
    "all_results.to_json (r'C:\\Users\\Kyle Ker\\Appl.json')\n",
    "all_results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
